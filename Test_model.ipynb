{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dependencies\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from glob import glob\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing the Model\n",
    "# my_model = load_model(\"C:/Users/tiwar/Desktop/Project_transfer_learning_model_20_epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load(filename):\n",
    "    image_classifier = 0\n",
    "    display_image = filename\n",
    "    # display_image = cv2.cvtColor(display_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if display_image.mean() > 125:\n",
    "        box_image = display_image[50:290, :]\n",
    "        image_classifier = 1\n",
    "    else:\n",
    "        box_image = display_image[30:430, :]\n",
    "        image_classifier = 2\n",
    "\n",
    "    prediction_image = Image.fromarray(box_image)\n",
    "    prediction_image = np.array(prediction_image).astype('float32') / 255\n",
    "    prediction_image = transform.resize(prediction_image, (224, 224, 3))\n",
    "    prediction_image = np.expand_dims(prediction_image, axis=0)\n",
    "\n",
    "    return prediction_image, box_image, display_image, image_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_box(input_image):\n",
    "    # Preprocess the image\n",
    "    gray_img = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Applying 7x7 Gaussian Blur\n",
    "    blurred = cv2.GaussianBlur(gray_img, (7, 7), 0)\n",
    "\n",
    "    # Applying threshold\n",
    "    threshold = cv2.threshold(\n",
    "        blurred, int(input_image.mean()) + 80, 255, cv2.THRESH_BINARY\n",
    "    )[1]\n",
    "\n",
    "    # Apply the Component analysis function\n",
    "    analysis = cv2.connectedComponentsWithStats(threshold, 4, cv2.CV_32S)\n",
    "    (totalLabels, label_ids, values, centroid) = analysis\n",
    "\n",
    "    # Initialize a new image to store all the output components\n",
    "    output = np.zeros(gray_img.shape, dtype=\"uint8\")\n",
    "    count = 0\n",
    "    rects = []\n",
    "        # Loop through each component\n",
    "    for i in range(1, totalLabels):\n",
    "        area = values[i, cv2.CC_STAT_AREA]\n",
    "        if (area > 30) and (area < 300):\n",
    "            componentMask = (label_ids == i).astype(\"uint8\") * 255\n",
    "            output = cv2.bitwise_or(output, componentMask)\n",
    "            x1 = values[i, cv2.CC_STAT_LEFT]\n",
    "            y1 = values[i, cv2.CC_STAT_TOP]\n",
    "            w = values[i, cv2.CC_STAT_WIDTH]\n",
    "            h = values[i, cv2.CC_STAT_HEIGHT]\n",
    "            pt1 = (x1 - 40, y1 - 40)\n",
    "            pt2 = (x1 + w + 40, y1 + h + 40)\n",
    "            rects.append([pt1, pt2])\n",
    "            count = count + 1\n",
    "\n",
    "    for i in rects:\n",
    "        cv2.rectangle(input_image, i[0], i[1], (0, 255, 0), 4)\n",
    "\n",
    "    return input_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_video = \"C:/Users/tiwar/Desktop/videos/24.avi\"\n",
    "cap = cv2.VideoCapture(source_video)\n",
    "count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    count += 1\n",
    "    frame_count = f\"Frame {count}\"\n",
    "    ret, frame = cap.read()\n",
    "    actual_image = frame.copy()\n",
    "    actual_image = cv2.resize(actual_image, (678, 384))\n",
    "    cv2.putText(actual_image, 'Actual_Video', org=(20, 25), fontFace=cv2.FONT_HERSHEY_TRIPLEX, \n",
    "                fontScale=0.5, color=(0, 0, 255), thickness=1)\n",
    "    cv2.putText(actual_image, frame_count, org=(200, 25), fontFace=cv2.FONT_HERSHEY_TRIPLEX, \n",
    "                fontScale=0.5, color=(0, 0, 255), thickness=1)\n",
    "\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    prediction_image, box_image, display_image, image_classifier = load(frame)\n",
    "    model_prediction = my_model.predict(prediction_image)\n",
    "\n",
    "    if model_prediction < 0.5:\n",
    "        box_image = make_box(box_image)\n",
    "        if image_classifier == 1:\n",
    "            display_image[50:290, :] = box_image\n",
    "        elif image_classifier == 2:\n",
    "            display_image[30:430, :] = box_image\n",
    "\n",
    "        display_image = cv2.resize(display_image, (678, 384))\n",
    "        cv2.putText(display_image, 'A06 Test analyzed_Video', org=(20, 25), fontFace=cv2.FONT_HERSHEY_TRIPLEX, \n",
    "                    fontScale=0.5, color=(0, 0, 255), thickness=1)\n",
    "        cv2.putText(display_image, frame_count, org=(200, 25), fontFace=cv2.FONT_HERSHEY_TRIPLEX, \n",
    "                    fontScale=0.5, color=(0, 0, 255), thickness=1)\n",
    "        cv2.putText(display_image, 'NG_Scratch Detected !!', org=(20, 350), fontFace=cv2.FONT_HERSHEY_TRIPLEX, \n",
    "                    fontScale=1, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "    else:\n",
    "        display_image = cv2.resize(display_image, (678, 384))\n",
    "        cv2.putText(display_image, 'A06 Test analyzed_Video', org=(20, 25), fontFace=cv2.FONT_HERSHEY_TRIPLEX, \n",
    "                    fontScale=0.5, color=(0, 0, 255), thickness=1)\n",
    "        cv2.putText(display_image, frame_count, org=(200, 25), fontFace=cv2.FONT_HERSHEY_TRIPLEX, \n",
    "                    fontScale=0.5, color=(0, 0, 255), thickness=1)\n",
    "        cv2.putText(display_image, 'OK_No Scratches Found', org=(20, 350), fontFace=cv2.FONT_HERSHEY_TRIPLEX, \n",
    "                    fontScale=1, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "    concatenated_image = np.concatenate((actual_image, display_image), axis=1)\n",
    "    cv2.imshow(\"A06 Scratch Detection Model\", concatenated_image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
